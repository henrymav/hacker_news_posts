{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*This is my second data science projectin Python. The aim of this project was to continue working with the fundamental Python tools and be more comfortable chaining methods and formatting outputs with new tehcniques. Thank you for reading!*\n",
    "\n",
    "# Hacker News - When should you ask your question?\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") receive votes and comments, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "The aim of the project is to compare the two types of posts submitted on Hacker News: \n",
    "1. Questions - asking the community\n",
    "2. Showcase - show the community a project, product, or just something intersting\n",
    "\n",
    "in order to determine:\n",
    "- which type of postsL `Ask HN` (Question) or `Show HN` (Showcase) recieves more comments\n",
    "- how the time of the day a certain post is created influences the amount of comments it recieves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "The datset can be downloaded [here](https://www.kaggle.com/datasets/hacker-news/hacker-news-posts?datasetId=197&sortBy=dateCreated).\n",
    "\n",
    "It contains data about posts submitten in the communityin a 12 month period (up to September 2016) and was originally put together by Hacker News in 2016. It has not been updated since. \n",
    "\n",
    "It originally has 300,000 rows. We have reduced it to approximately 20,000 rows by removing all submissions that didn't receive any comments and then randomly sampling from the remaining submissions.\n",
    "\n",
    "Below are descriptions of the columns:\n",
    "\n",
    "| Column Name in Dataset    | Description |\n",
    "| :---------     | ----------: |\n",
    "| \"id\"           | the unique identifier from Hacker News for the post |\n",
    "| \"title\"   | the title of the post  |\n",
    "| \"url\"   | the URL that the posts links to, if the post has a URL |\n",
    "| \"num_points\"     | the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes |\n",
    "| \"num_comments\"     | the number of comments on the post |\n",
    "| \"author\"     | the username of the person who submitted the post |\n",
    "| \"created_at\"     | the date and time of the post's submission\n",
    " |\n",
    " \n",
    " \n",
    "For the purposes of this project, the columns of interest to us are: `num_comments` and ` created_at`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries \n",
    "#csv and datetime\n",
    "\n",
    "from csv import reader\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the dataset and display the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opened_file = open ('hacker_news.csv')\n",
    "read_file = reader (opened_file)\n",
    "hn = list (read_file)\n",
    "hn [:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01'],\n",
       " ['10301696',\n",
       "  'Note by Note: The Making of Steinway L1037 (2007)',\n",
       "  'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
       "  '8',\n",
       "  '2',\n",
       "  'walterbell',\n",
       "  '9/30/2015 4:12']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = hn [0]\n",
    "hn = hn [1:]\n",
    "print(headers)\n",
    "'\\n'\n",
    "hn [:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Ask HN and Show HN Posts\n",
    "\n",
    "As we are interested in comparing the Question and Showcase type submissions, we will split them into two lists by using the string method `startswith`. To ensure that we have take into account all posts, we will  use the `lower` method to convert all title strings to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask posts: 1744\n",
      "Show Posts: 1162\n",
      "Other Posts: 17194\n"
     ]
    }
   ],
   "source": [
    "#creating empty lists to store the different types of posts\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "#looping over eac row in the hn dataset to populate the posts into the appropriate lists\n",
    "for row in hn:\n",
    "    title = row [1] \n",
    "    if title.lower().startswith('ask hn') is True:\n",
    "        ask_posts.append (row)\n",
    "    elif title.lower().startswith ('show hn') is True:\n",
    "        show_posts.append (row)\n",
    "    else:\n",
    "        other_posts.append (row)\n",
    "\n",
    "print ('Ask posts:' , len (ask_posts))\n",
    "print ('Show Posts:' , len (show_posts))\n",
    "print ('Other Posts:', len (other_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ensure we have collected the right posts in each list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12296411',\n",
       "  'Ask HN: How to improve my personal website?',\n",
       "  '',\n",
       "  '2',\n",
       "  '6',\n",
       "  'ahmedbaracat',\n",
       "  '8/16/2016 9:55'],\n",
       " ['10610020',\n",
       "  'Ask HN: Am I the only one outraged by Twitter shutting down share counts?',\n",
       "  '',\n",
       "  '28',\n",
       "  '29',\n",
       "  'tkfx',\n",
       "  '11/22/2015 13:43'],\n",
       " ['11610310',\n",
       "  'Ask HN: Aby recent changes to CSS that broke mobile?',\n",
       "  '',\n",
       "  '1',\n",
       "  '1',\n",
       "  'polskibus',\n",
       "  '5/2/2016 10:14']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_posts [:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10627194',\n",
       "  'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform',\n",
       "  'https://iot.seeed.cc',\n",
       "  '26',\n",
       "  '22',\n",
       "  'kfihihc',\n",
       "  '11/25/2015 14:03'],\n",
       " ['10646440',\n",
       "  'Show HN: Something pointless I made',\n",
       "  'http://dn.ht/picklecat/',\n",
       "  '747',\n",
       "  '102',\n",
       "  'dhotson',\n",
       "  '11/29/2015 22:46'],\n",
       " ['11590768',\n",
       "  'Show HN: Shanhu.io, a programming playground powered by e8vm',\n",
       "  'https://shanhu.io',\n",
       "  '1',\n",
       "  '1',\n",
       "  'h8liu',\n",
       "  '4/28/2016 18:05']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_posts [:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Average Number of Comments for Ask HN and Show HN Posts\n",
    "\n",
    "Which posts recieve more comments? Let's compare the averages for these two types of posts. In order to do this, we will:\n",
    "1. Determine the total amount of comments for each post type\n",
    "2. Divide by the amount of posts in each 'category': ask or show\n",
    "3. Compare the two figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comments per \"Ask\" post: 14.038417431192661\n",
      "Average comments per \"Show\" post: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "#creating new variable and set it to 0 in order to use it as a variable for an equation\n",
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    comments = int (post [4])\n",
    "    total_ask_comments += comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print ('Average comments per \"Ask\" post:', avg_ask_comments)\n",
    "\n",
    "#repeating the steps for show_comments\n",
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    comments = int (post [4])\n",
    "    total_show_comments += comments\n",
    "    \n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print ('Average comments per \"Show\" post:', avg_show_comments)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that *Ask* comments recieve more comments on average (14) compared to *Show* comments (10.3).\n",
    "\n",
    "Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the number of Ask Posts and Comments by hour created\n",
    "\n",
    "1. Calculate the number of ask posts created in each hour of the day, along with the number of comments received.\n",
    "    - Extract time and number of comments per post\n",
    "    - Clean `created_at` column to extract time (in 24h format) of the day\n",
    "    - Create frequency table for posts created in each hour of the day\n",
    "    - Create frequency table for comments created in each hour of the day - based on the comments of each post in that hour\n",
    "2. Calculate the average number of comments ask posts receive by hour created.\n",
    "    - Divide the comment count frequency value by the posts created frequency value based on their corresponding dictionary key value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8/16/2016 9:55', 6],\n",
       " ['11/22/2015 13:43', 29],\n",
       " ['5/2/2016 10:14', 1],\n",
       " ['8/2/2016 14:20', 3],\n",
       " ['10/15/2015 16:38', 17]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    created_at = post [6]\n",
    "    comments = int (post[4])\n",
    "    results_list.append ([created_at, comments])\n",
    "\n",
    "results_list [:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('00', 447)\n",
      "('01', 683)\n",
      "('02', 1381)\n",
      "('03', 421)\n",
      "('04', 337)\n",
      "('05', 464)\n",
      "('06', 397)\n",
      "('07', 267)\n",
      "('08', 492)\n",
      "('09', 251)\n",
      "('10', 793)\n",
      "('11', 641)\n",
      "('12', 687)\n",
      "('13', 1253)\n",
      "('14', 1416)\n",
      "('15', 4477)\n",
      "('16', 1814)\n",
      "('17', 1146)\n",
      "('18', 1439)\n",
      "('19', 1188)\n",
      "('20', 1722)\n",
      "('21', 1745)\n",
      "('22', 479)\n",
      "('23', 543)\n"
     ]
    }
   ],
   "source": [
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = '%m/%d/%Y %H:%M' #instantiating datetime object, which will be second argument in our strptime methord\n",
    "\n",
    "for row in results_list:\n",
    "    date = row [0]\n",
    "    time = dt.datetime.strptime(date,date_format).strftime('%H') #extracting only hour (in 24h format)\n",
    "    if time not in counts_by_hour:\n",
    "        counts_by_hour[time] = 1\n",
    "        comments_by_hour[time] = int(row [1])\n",
    "    else:\n",
    "        counts_by_hour[time] += 1\n",
    "        comments_by_hour[time] += int (row[1])\n",
    "\n",
    "#presenting the comments by hour in order of the hour of the day\n",
    "sorted_comments = sorted(comments_by_hour.items(), key=lambda x:x[0]) #we are sorting by key, not value, hence the '0'\n",
    "for item in sorted_comments:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find out the average comment by hour of the day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append ([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print it in a more eye-friendly way to see which hours of the day have the most comments per post for the Ask posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['00', 8.127272727272727],\n",
       " ['01', 11.383333333333333],\n",
       " ['02', 23.810344827586206],\n",
       " ['03', 7.796296296296297],\n",
       " ['04', 7.170212765957447],\n",
       " ['05', 10.08695652173913],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['08', 10.25],\n",
       " ['09', 5.5777777777777775],\n",
       " ['10', 13.440677966101696],\n",
       " ['11', 11.051724137931034],\n",
       " ['12', 9.41095890410959],\n",
       " ['13', 14.741176470588234],\n",
       " ['14', 13.233644859813085],\n",
       " ['15', 38.5948275862069],\n",
       " ['16', 16.796296296296298],\n",
       " ['17', 11.46],\n",
       " ['18', 13.20183486238532],\n",
       " ['19', 10.8],\n",
       " ['20', 21.525],\n",
       " ['21', 16.009174311926607],\n",
       " ['22', 6.746478873239437],\n",
       " ['23', 7.985294117647059]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_list = sorted({tuple(x): x for x in avg_by_hour}.values())\n",
    "sorted_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list gives us a clear understanding of how comments per ask post variate throughout the day, but not which are the top hours for posts to recieve most comments. \n",
    "\n",
    "Let's print a list in order of highest average comments per post to find out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.5777777777777775, '09'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [16.796296296296298, '16'],\n",
       " [7.985294117647059, '23'],\n",
       " [9.41095890410959, '12'],\n",
       " [11.46, '17'],\n",
       " [38.5948275862069, '15'],\n",
       " [16.009174311926607, '21'],\n",
       " [21.525, '20'],\n",
       " [23.810344827586206, '02'],\n",
       " [13.20183486238532, '18'],\n",
       " [7.796296296296297, '03'],\n",
       " [10.08695652173913, '05'],\n",
       " [10.8, '19'],\n",
       " [11.383333333333333, '01'],\n",
       " [6.746478873239437, '22'],\n",
       " [10.25, '08'],\n",
       " [7.170212765957447, '04'],\n",
       " [8.127272727272727, '00'],\n",
       " [9.022727272727273, '06'],\n",
       " [7.852941176470588, '07'],\n",
       " [11.051724137931034, '11']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for hour in avg_by_hour:\n",
    "    swap_avg_by_hour.append ([hour[1], hour[0]])\n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print ('Top 5 Hours for Ask Posts Comments')\n",
    "\n",
    "for avg,hr in sorted_swap[:5]:\n",
    "    print( \n",
    "        '{}: {:.2f} average comments per post'\n",
    "    .format(dt.datetime.strptime(hr,'%H').strftime('%H:%M'), avg)\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations for analysis\n",
    "\n",
    "We can see that the top time is 15:00, 3 o'clock in the afternoon. It is interesting to see how spread out these times are, though there are 2 two-hour intervals: `15:00` & `16:00`, and `20:00` & `21:00` which feature among the top 5, indicating an increase in activity during those hours. \n",
    "\n",
    "One could argue these hours are when students finish college or shcool (`15:00` & `16:00`).  The other time interval (`20:00` & `21:00`) is on average after dinner, which is when professionals or enthusiasts after daily schedules would most likely be on the platform. This second time slot could also correspond to people submitting posts after school or work activities. \n",
    "\n",
    "There is also a surge at 2am, `02:00`, which could be related some members in the community posting during unusual hours or corresponding to the morning in Europe.\n",
    "\n",
    "As is specifified in the documentation:\n",
    "> `created_at`: the date and time the post was made (the time zone is Eastern Time in the US)\n",
    "\n",
    "therefore the `02:00` slot could correspond to the morning in Europe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, if you want to get high engagement in your question-related posts, you should post between 3pm and 5pm ET. You should abstain from posting before the afternoon (in US timezone). This is evidenced by an overall higher comments per post average starting from 2pm ET onwards. The higher engagement drops off after 10pm ET, with a resurgence from 1am to 3am ET. \n",
    "\n",
    "With additional data such as georgraphy of the user, it could be possible to see how these trends in hours are due to different regions. Hacker News being a predominantly English-speaking website, I will assume for the time being that these variations are due to user activity in North America and Europe, where English is more widespread as a language for news and blogging. \n",
    "\n",
    "Furthermore, these conclusions are drawn from a sample in the dataset and with more data instances at our disposal, the results may vary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
