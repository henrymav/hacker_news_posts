{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*This is my second data science projectin Python. The aim of this project was to continue working with the fundamental Python tools and be more comfortable chaining methods and formatting outputs with new tehcniques. Thank you for reading!*\n",
    "\n",
    "# Hacker News - When should you ask your question?\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator on which user-submitted stories (known as \"posts\") receive votes and comments, similar to Reddit. Hacker News is extremely popular in technology and startup circles. Posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "The aim of the project is to compare the two types of posts submitted on Hacker News: \n",
    "1. Questions - asking the community\n",
    "2. Showcase - show the community a project, product, or just something intersting\n",
    "\n",
    "in order to determine\n",
    "- which type of posts Question - `Ask HN`  or Showcase - `Show HN` recieves more comments\n",
    "- how the time of the day a certain post is created influences the amount of comments it recieves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "The datset can be downloaded [here](https://www.kaggle.com/datasets/hacker-news/hacker-news-posts?datasetId=197&sortBy=dateCreated).\n",
    "\n",
    "It contains data about posts submitten in the community in a 12 month period (up to September 2016) and was originally put together by Hacker News in 2016. It has not been updated since. \n",
    "\n",
    "It originally consists of 300,000 rows. The dataset was reduced to approximately 20,000 rows by removing all submissions that didn't receive any comments and then randomly sampling from the remaining submissions.\n",
    "\n",
    "Below are descriptions of the columns:\n",
    "\n",
    "| Column Name in Dataset    | Description |\n",
    "| :---------     | ----------: |\n",
    "| \"id\"           | the unique identifier from Hacker News for the post |\n",
    "| \"title\"   | the title of the post  |\n",
    "| \"url\"   | the URL that the posts links to, if the post has a URL |\n",
    "| \"num_points\"     | the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes |\n",
    "| \"num_comments\"     | the number of comments on the post |\n",
    "| \"author\"     | the username of the person who submitted the post |\n",
    "| \"created_at\"     | the date and time of the post's submission\n",
    " |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "\n",
    "from csv import reader\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the dataset and display the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opened_file = open ('hacker_news.csv')\n",
    "read_file = reader (opened_file)\n",
    "hn = list (read_file)\n",
    "hn [:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01'],\n",
       " ['10301696',\n",
       "  'Note by Note: The Making of Steinway L1037 (2007)',\n",
       "  'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
       "  '8',\n",
       "  '2',\n",
       "  'walterbell',\n",
       "  '9/30/2015 4:12']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = hn [0]\n",
    "hn = hn [1:]\n",
    "print(headers)\n",
    "'\\n'\n",
    "hn [:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this project, the columns of interest to us are: `num_comments` as it tells us the number of comments on a post and ` created_at` which will provide us with data on when the post was submitted by a user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating datasets of the question and showcase posts\n",
    "\n",
    "We are interested in comparing the Question and Showcase posts. We will split them into two lists by using the string method `startswith`. To ensure that we have taken into account all posts, we will use the `lower` method to convert all title strings to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask posts: 1744\n",
      "Show Posts: 1162\n",
      "Other Posts: 17194\n"
     ]
    }
   ],
   "source": [
    "#creating empty lists to store the different types of posts\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "#looping over eac row in the hn dataset to populate the posts into the appropriate lists\n",
    "for row in hn:\n",
    "    title = row [1] \n",
    "    if title.lower().startswith('ask hn') is True:\n",
    "        ask_posts.append (row)\n",
    "    elif title.lower().startswith ('show hn') is True:\n",
    "        show_posts.append (row)\n",
    "    else:\n",
    "        other_posts.append (row)\n",
    "\n",
    "print ('Ask posts:' , len (ask_posts))\n",
    "print ('Show Posts:' , len (show_posts))\n",
    "print ('Other Posts:', len (other_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ensure we have collected the right posts in each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12296411',\n",
       "  'Ask HN: How to improve my personal website?',\n",
       "  '',\n",
       "  '2',\n",
       "  '6',\n",
       "  'ahmedbaracat',\n",
       "  '8/16/2016 9:55'],\n",
       " ['10610020',\n",
       "  'Ask HN: Am I the only one outraged by Twitter shutting down share counts?',\n",
       "  '',\n",
       "  '28',\n",
       "  '29',\n",
       "  'tkfx',\n",
       "  '11/22/2015 13:43'],\n",
       " ['11610310',\n",
       "  'Ask HN: Aby recent changes to CSS that broke mobile?',\n",
       "  '',\n",
       "  '1',\n",
       "  '1',\n",
       "  'polskibus',\n",
       "  '5/2/2016 10:14']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_posts [:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10627194',\n",
       "  'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform',\n",
       "  'https://iot.seeed.cc',\n",
       "  '26',\n",
       "  '22',\n",
       "  'kfihihc',\n",
       "  '11/25/2015 14:03'],\n",
       " ['10646440',\n",
       "  'Show HN: Something pointless I made',\n",
       "  'http://dn.ht/picklecat/',\n",
       "  '747',\n",
       "  '102',\n",
       "  'dhotson',\n",
       "  '11/29/2015 22:46'],\n",
       " ['11590768',\n",
       "  'Show HN: Shanhu.io, a programming playground powered by e8vm',\n",
       "  'https://shanhu.io',\n",
       "  '1',\n",
       "  '1',\n",
       "  'h8liu',\n",
       "  '4/28/2016 18:05']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_posts [:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Average Number of Comments for Ask HN and Show HN Posts\n",
    "\n",
    "We will compare the averages for these two types of posts to determine which one recieves more comments. To do so we will:\n",
    "1. Determine the total amount of comments for each post type\n",
    "2. Divide by the amount of posts in each list ( `ask_posts` and `show_posts`) to compute the average comments per type of post\n",
    "3. Compare the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comments per \"Ask\" post: 14.038417431192661\n",
      "Average comments per \"Show\" post: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "#creating new variable and set it to 0 in order to use it as a variable for an equation\n",
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    comments = int (post [4])\n",
    "    total_ask_comments += comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print ('Average comments per \"Ask\" post:', avg_ask_comments)\n",
    "\n",
    "#repeating the steps for show_comments\n",
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    comments = int (post [4])\n",
    "    total_show_comments += comments\n",
    "    \n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print ('Average comments per \"Show\" post:', avg_show_comments)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that on average `ask_posts` recieve more comments (14) than `show_posts` (10).\n",
    "\n",
    "As `ask_posts` are more likely to receive comments, we willl focus our analysis on these types of posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the number of comments by hour for ask posts \n",
    "\n",
    "We will find the number of comments on `ask_posts` by hour in two steps.\n",
    "\n",
    "1. Calculating the number of ask posts submitted in each hour of the day with the corresponding amount of comments received on those posts. \n",
    "    - Extracting submission time of the post and the number of comments for that post\n",
    "    - Cleaning the `created_at` column to extract the time (in 24h format) of the day\n",
    "    - Creating a frequency table for posts created in each hour of the day\n",
    "    - Creating a frequency table for comments created in each hour of the day - based on the comments of each post in that hour\n",
    "    \n",
    "\n",
    "2. Calculating the average amount of comments ask posts receive by hour of the day in which they are submitted.\n",
    "    - Dividing the 'comment count' frequency value by the 'posts created' frequency value based on their corresponding dictionary key value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8/16/2016 9:55', 6],\n",
       " ['11/22/2015 13:43', 29],\n",
       " ['5/2/2016 10:14', 1],\n",
       " ['8/2/2016 14:20', 3],\n",
       " ['10/15/2015 16:38', 17]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    created_at = post [6]\n",
    "    comments = int (post[4])\n",
    "    results_list.append ([created_at, comments])\n",
    "\n",
    "results_list [:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('00', 447)\n",
      "('01', 683)\n",
      "('02', 1381)\n",
      "('03', 421)\n",
      "('04', 337)\n",
      "('05', 464)\n",
      "('06', 397)\n",
      "('07', 267)\n",
      "('08', 492)\n",
      "('09', 251)\n",
      "('10', 793)\n",
      "('11', 641)\n",
      "('12', 687)\n",
      "('13', 1253)\n",
      "('14', 1416)\n",
      "('15', 4477)\n",
      "('16', 1814)\n",
      "('17', 1146)\n",
      "('18', 1439)\n",
      "('19', 1188)\n",
      "('20', 1722)\n",
      "('21', 1745)\n",
      "('22', 479)\n",
      "('23', 543)\n"
     ]
    }
   ],
   "source": [
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = '%m/%d/%Y %H:%M' #instantiating a datetime object, which will be the second argument in our strptime method\n",
    "\n",
    "for row in results_list:\n",
    "    date = row [0]\n",
    "    time = dt.datetime.strptime(date,date_format).strftime('%H') #extracting only hour (in 24h format)\n",
    "    if time not in counts_by_hour:\n",
    "        counts_by_hour[time] = 1\n",
    "        comments_by_hour[time] = int(row [1])\n",
    "    else:\n",
    "        counts_by_hour[time] += 1\n",
    "        comments_by_hour[time] += int (row[1])\n",
    "\n",
    "#presenting the comments by hour in order of the hour of the day\n",
    "sorted_comments = sorted(comments_by_hour.items(), key=lambda x:x[0]) #we are sorting by key\n",
    "for item in sorted_comments:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the average comments per post by hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append ([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the list in chronological order to see which hours of the day have the most comments per post for the `ask_posts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['00', 8.127272727272727],\n",
       " ['01', 11.383333333333333],\n",
       " ['02', 23.810344827586206],\n",
       " ['03', 7.796296296296297],\n",
       " ['04', 7.170212765957447],\n",
       " ['05', 10.08695652173913],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['08', 10.25],\n",
       " ['09', 5.5777777777777775],\n",
       " ['10', 13.440677966101696],\n",
       " ['11', 11.051724137931034],\n",
       " ['12', 9.41095890410959],\n",
       " ['13', 14.741176470588234],\n",
       " ['14', 13.233644859813085],\n",
       " ['15', 38.5948275862069],\n",
       " ['16', 16.796296296296298],\n",
       " ['17', 11.46],\n",
       " ['18', 13.20183486238532],\n",
       " ['19', 10.8],\n",
       " ['20', 21.525],\n",
       " ['21', 16.009174311926607],\n",
       " ['22', 6.746478873239437],\n",
       " ['23', 7.985294117647059]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_list = sorted({tuple(x): x for x in avg_by_hour}.values())\n",
    "sorted_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list shows us clearly how comments per `ask_posts` fluctuate throughout the day.\n",
    "\n",
    "Let's print the list in order of highest average comments per hour to find out when users should posts their comments to get the highest engagement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.5777777777777775, '09'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [16.796296296296298, '16'],\n",
       " [7.985294117647059, '23'],\n",
       " [9.41095890410959, '12'],\n",
       " [11.46, '17'],\n",
       " [38.5948275862069, '15'],\n",
       " [16.009174311926607, '21'],\n",
       " [21.525, '20'],\n",
       " [23.810344827586206, '02'],\n",
       " [13.20183486238532, '18'],\n",
       " [7.796296296296297, '03'],\n",
       " [10.08695652173913, '05'],\n",
       " [10.8, '19'],\n",
       " [11.383333333333333, '01'],\n",
       " [6.746478873239437, '22'],\n",
       " [10.25, '08'],\n",
       " [7.170212765957447, '04'],\n",
       " [8.127272727272727, '00'],\n",
       " [9.022727272727273, '06'],\n",
       " [7.852941176470588, '07'],\n",
       " [11.051724137931034, '11']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for hour in avg_by_hour:\n",
    "    swap_avg_by_hour.append ([hour[1], hour[0]])\n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print ('Top 5 Hours for Ask Posts Comments')\n",
    "\n",
    "for avg,hr in sorted_swap[:5]:\n",
    "    print( \n",
    "        '{}: {:.2f} average comments per post'\n",
    "    .format(dt.datetime.strptime(hr,'%H').strftime('%H:%M'), avg)\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations \n",
    "\n",
    "We can see that the top time is `15:00`, 3 o'clock in the afternoon. There are two two-hour intervals: `15:00` & `16:00`, and `20:00` & `21:00` which feature among in the top 5 average comments per post, indicating an increase in engagement for posts submitted at those hours. \n",
    "\n",
    "One could argue these hours are when students finish college or shcool (`15:00` & `16:00`). The other time interval (`20:00` & `21:00`) is one could say after dinner, which is when professionals or enthusiasts with busier daily schedules would be more likely to spend time on the platform. This second time slot in which comments get increased engagement could also correspond to people submitting posts after school or work activities. \n",
    "\n",
    "There is also a surge at 2 o'clock in the morning `02:00`,\n",
    "\n",
    "In the documentation, it is specified that the\n",
    "> `created_at` column corresponds to: the date and time the post was made (the time zone is Eastern Time in the US)\n",
    "\n",
    "which could explain higher engagement of posts submitted at 2 o'clock due to it being the morning in Europe or individuals engaging late if on the American continents. \n",
    "\n",
    "It it crucial to note that we do not have data on the time at which the comments are made on the posts. Submissions may be commented on any time after a post is submitted. This means the time at which the post was submitted should not be taken as an indicator of time when posts are commented on. We can assume that posts will likely get more comments in the hours and days that follow its submission by the user but not all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, if an individual posting on Hacker News wants to get high engagement in their question-related posts, they should consider submitting their post between 3pm and 5pm ET. They should abstain from posting before the afternoon (in ET timezone). This is evidenced by an overall higher comments per post average starting from 2pm ET onwards. The engagement beings dropping off after 10pm ET, with a resurgence from 1am to 3am ET. We arrived at this conclusion by looking at data of when posts are submitted and computing the average amount of comments posts recieved during the hours of the day.\n",
    "\n",
    "With additional data, for instance geographical, we could confirm our hypotheses whether the variation of engagement by hours is due to geographical differences. Hacker News is predominantly an English-speaking website, and we may assume that the two ranges of time with a number of comments per post are due to user activity in North America and Europe where English is a more widespread language for news and blogging. \n",
    "\n",
    "These conclusions are based on a sample of data and therefore limits our ability to generalize these findings for users posting globally on the Hacker News website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
